

<!DOCTYPE html>
<html lang="en">
<head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8"/>
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script
            src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"
    ></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
            integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
            integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
            crossorigin="anonymous"></script>


    <!-- Library libs_ext -->
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>


    <!--    Internal Libs -->
    <script src="static/js/data/api.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY="
          crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
            href="static/css/Lato.css"
            rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet"/>
    <link
            href="static/css/Cuprum.css"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="static/css/main.css"/>
<!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css"/>
    <link rel="stylesheet" href="static/css/typeahead.css"/>

    <title>DLG4NLP: Fast Neural Network Adaptation via Parameter Remapping and Architecture Search</title>
    
<meta name="citation_title" content="Fast Neural Network Adaptation via Parameter Remapping and Architecture Search"/>

<meta name="citation_author" content="Jiemin Fang*"/>

<meta name="citation_author" content="Yuzhu Sun*"/>

<meta name="citation_author" content="Kangjian Peng*"/>

<meta name="citation_author" content="Qian Zhang"/>

<meta name="citation_author" content="Yuan Li"/>

<meta name="citation_author" content="Wenyu Liu"/>

<meta name="citation_author" content="Xinggang Wang"/>

<meta name="citation_publication_date" content=""/>
<meta name="citation_conference_title"
      content="Deep Learning On Graphs For Natural Language Processing"/>
<meta name="citation_inbook_title" content=""/>
<meta name="citation_abstract" content="Deep neural networks achieve remarkable performance in many computer vision tasks. Most state-of-the-art~(SOTA) semantic segmentation and object detection approaches reuse neural network architectures designed for image classification as the backbone, commonly pre-trained on ImageNet. However, performance gains can be achieved by designing network architectures specifically for detection and segmentation, as shown by recent neural architecture search (NAS) research for detection and segmentation. One major challenge though, is that ImageNet pre-training of the search space representation (a.k.a. super network) or the searched networks incurs huge computational cost. In this paper, we propose a Fast Neural Network Adaptation (FNA) method, which can adapt both the architecture and parameters of a seed network (e.g. a high performing manually designed backbone) to become a network with different depth, width, or kernels via a Parameter Remapping technique, making it possible to utilize NAS for detection/segmentation tasks a lot more efficiently. In our experiments, we conduct FNA on MobileNetV2 to obtain new networks for both segmentation and detection that clearly out-perform existing networks designed both manually and by NAS. The total computation cost of FNA is significantly less than SOTA segmentation/detection NAS approaches: 1737$\times$ less than DPC, 6.8$\times$ less than Auto-DeepLab and 7.4$\times$ less than DetNAS. The code is available at https://github.com/JaminFong/FNA ."/>

<meta name="citation_keywords" content="computer vision"/>

<meta name="citation_keywords" content="imagenet"/>

<meta name="citation_keywords" content="neural architecture search"/>

<meta name="citation_keywords" content="semantic segmentation"/>

<meta name="citation_pdf_url" content=""/>


</head>

<body>
<!-- NAV -->

<nav
        class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
        id="main-nav"
>
    <div class="container">
        <a class="navbar-brand" href="index.html">
            <img
                    class="logo" src="static/images/G4L-logo.png"
                    height="auto"
            width="200px"
            />
        </a>
        
        <button
                class="navbar-toggler"
                type="button"
                data-toggle="collapse"
                data-target="#navbarNav"
                aria-controls="navbarNav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div
                class="collapse navbar-collapse text-right flex-grow-1"
                id="navbarNav"
        >
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="index.html">Home</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="papers.html">Paper</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="workshops.html">Workshop</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="https://drive.google.com/file/d/1_7cPySt9Pzfd6MaqNihD4FkKI0qzf-s4/view
">Tutorial</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="https://github.com/graph4ai/graph4nlp_demo">Demo</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="http://saizhuo.wang/g4nlp/index.html">Docs</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="https://github.com/graph4ai/graph4nlp">GitHub</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="blogs.html">Blog</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>



<!-- User Overrides -->
 

<div class="container">
    <!-- Tabs -->
    <div class="tabs">
         
    </div>
    <!-- Content -->
    <div class="content">
        

<!-- Title -->
<div class="pp-card m-3" style="">
    <div class="card-header">
        <h2 class="card-title main-title text-center" style="">
            Fast Neural Network Adaptation via Parameter Remapping and Architecture Search
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?filter=authors&search=Jiemin Fang*"
               class="text-muted"
            >Jiemin Fang*</a
            >,
            
            <a href="papers.html?filter=authors&search=Yuzhu Sun*"
               class="text-muted"
            >Yuzhu Sun*</a
            >,
            
            <a href="papers.html?filter=authors&search=Kangjian Peng*"
               class="text-muted"
            >Kangjian Peng*</a
            >,
            
            <a href="papers.html?filter=authors&search=Qian Zhang"
               class="text-muted"
            >Qian Zhang</a
            >,
            
            <a href="papers.html?filter=authors&search=Yuan Li"
               class="text-muted"
            >Yuan Li</a
            >,
            
            <a href="papers.html?filter=authors&search=Wenyu Liu"
               class="text-muted"
            >Wenyu Liu</a
            >,
            
            <a href="papers.html?filter=authors&search=Xinggang Wang"
               class="text-muted"
            >Xinggang Wang</a
            >
            
        </h3>
        <p class="card-text text-center">
            <span class="">Keywords:</span>
            
            <a
                    href="papers.html?filter=keywords&search=computer vision"
                    class="text-secondary text-decoration-none"
            >computer vision</a
            >,
            
            <a
                    href="papers.html?filter=keywords&search=imagenet"
                    class="text-secondary text-decoration-none"
            >imagenet</a
            >,
            
            <a
                    href="papers.html?filter=keywords&search=neural architecture search"
                    class="text-secondary text-decoration-none"
            >neural architecture search</a
            >,
            
            <a
                    href="papers.html?filter=keywords&search=semantic segmentation"
                    class="text-secondary text-decoration-none"
            >semantic segmentation</a
            >
            
        </p>
        <div class="text-center p-3">
            <a class="card-link" data-toggle="collapse" role="button"
               href="#details">
                Abstract
            </a>
            <a class="card-link" target="_blank" href="https://arxiv.org/abs/2007.12238">
                Paper
            </a>
            
            <a href="https://github.com/Mini-Conf/Mini-Conf" target="_blank" class="card-link">
                Code
            </a>
            
        </div>
    </div>
</div>
<div id="details" class="pp-card m-3 collapse">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                Deep neural networks achieve remarkable performance in many computer vision tasks. Most state-of-the-art~(SOTA) semantic segmentation and object detection approaches reuse neural network architectures designed for image classification as the backbone, commonly pre-trained on ImageNet. However, performance gains can be achieved by designing network architectures specifically for detection and segmentation, as shown by recent neural architecture search (NAS) research for detection and segmentation. One major challenge though, is that ImageNet pre-training of the search space representation (a.k.a. super network) or the searched networks incurs huge computational cost. In this paper, we propose a Fast Neural Network Adaptation (FNA) method, which can adapt both the architecture and parameters of a seed network (e.g. a high performing manually designed backbone) to become a network with different depth, width, or kernels via a Parameter Remapping technique, making it possible to utilize NAS for detection/segmentation tasks a lot more efficiently. In our experiments, we conduct FNA on MobileNetV2 to obtain new networks for both segmentation and detection that clearly out-perform existing networks designed both manually and by NAS. The total computation cost of FNA is significantly less than SOTA segmentation/detection NAS approaches: 1737$\times$ less than DPC, 6.8$\times$ less than Auto-DeepLab and 7.4$\times$ less than DetNAS. The code is available at https://github.com/JaminFong/FNA .
            </div>
        </div>
        <p></p>
    </div>
</div>

<h5 style="color: red;">
    Add content for posters. This could be a video, embedded pdf, chat room ....
</h5>

<!-- Chat -->
<div class="border-top my-3"></div>
<div class="row p-4" id="faq">
  <div class="col-12 bd-content">
    <h2 class="text-center">Example Chat</h2>
  </div>
</div>

<div class="col-md-12 col-xs-12 p-2">
    <div id="gitter" class="slp">
        <center>
            <iframe frameborder="0"
                    src="https:///channel/paper_rklTmyBKPH?layout=embedded"
                    height="700px" width="100%"></iframe>
        </center>
    </div>
</div>

<!-- Slides Live-->

<div class="border-top my-3"></div>
<div class="row p-4" id="faq">
  <div class="col-12 bd-content">
    <h2 class="text-center">Example SlidesLive</h2>
  </div>
</div>

<div class="col-md-12 col-xs-12 my-auto p-2">
    <div id="presentation-embed" class="slp my-auto"></div>
    <script src='https://slideslive.com/embed_presentation.js'></script>
    <script>
      embed = new SlidesLiveEmbed("presentation-embed", {
        presentationId:
          "",
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 500,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true,
      });
    </script>
</div>


<!-- Chat -->

<div class="border-top my-3"></div>
<div class="row p-4" id="faq">
  <div class="col-12 bd-content">
    <h2 class="text-center">Example Poster</h2>
  </div>
</div>

<div role="main" id="pdf_view"></div>


<script src="https://cdn.jsdelivr.net/npm/pdfjs-dist@2.3.200/build/pdf.min.js"></script>
<script src="static/js/modules/pdfRender.js"></script>
<script>
  $(document).ready(() => {
    // render first page of PDF to div
    // PDF name can be bound to variable -- e.g. paper.content.poster_link
    const pdfFile =
      " ";
    initPDFViewer(pdfFile, "#pdf_view");
  });
</script>



    </div>
</div>



<!-- Google Analytics -->
<script
        async
        src="https://www.googletagmanager.com/gtag/js?id=UA-"
></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag("js", new Date());
  gtag("config", "UA-");
</script>

<!-- Footer -->
<footer class="footer bg-light p-4">
    <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2020 DLG4NLP Team</p>
    </div>
</footer>

<!-- Code for hash tags -->
<script type="text/javascript">
  $(document).ready(function () {
    if (window.location.hash !== "") {
      $(`a[href="${window.location.hash}"]`).tab("show");
    }

    $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
      const hash = $(e.target).attr("href");
      if (hash.substr(0, 1) === "#") {
        const position = $(window).scrollTop();
        window.location.replace(`#${hash.substr(1)}`);
        $(window).scrollTop(position);
      }
    });
  });
</script>
<!--    <script src="static/js/modules/lazyLoad.js"></script>-->

</body>
</html>