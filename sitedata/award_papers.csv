UID,title,authors,track,abstract,presentation_id,presentation_id_intro,pdf_url,date1,time1,date2,time2,room_letter1,room_letter2,room,cluster,position,cluster_name,gather_town_link
CLASSIC-2021,DL-Lite: Tractable Description Logics for Ontologies (2021 AAAI Classic Paper Award),Diego Calvanese|Giuseppe De Giacomo|Domenico Lembo|Maurizio Lenzerini|Riccardo Rosati,2021 AAAI Classic Paper Award,"We propose a new Description Logic, called DL-Lite, specif-ically tailored to capture basic ontology languages, whilekeeping low complexity of reasoning. Reasoning here meansnot only computing subsumption between concepts, andchecking satisfiability of the whole knowledge base, butalso answering complex queries (in particular, conjunctivequeries) over the set of instances maintained in secondarystorage. We show that in DL-Lite the usual DL reasoningtasks are polynomial in the size of the TBox, and query an-swering is polynomial in the size of the ABox (i.e., in datacomplexity). To the best of our knowledge, this is the first re-sult of polynomial data complexity for query answering overDL knowledge bases. A notable feature of our logic is to al-low for a separation between TBox and ABox reasoning dur-ing query evaluation: the part of the process requiring TBoxreasoning is independent of the ABox, and the part of theprocess requiring access to the ABox can be carried out by anSQL engine, thus taking advantage of the query optimizationstrategies provided by current DBMSs.",38951739,,http://www.aaai.org/Papers/AAAI/2005/AAAI05-094.pdf,4-Feb,,,,Y,,Award-D1-,,,2021 AAAI Classic Paper Award,http://widget1.virtualchair.net/custom/aaai/jump?paperId=CLASSIC-2021
DISS-2019,Learning to See the Physical World (2019 AAAI/ACM SIGAI Dissertation Award),Jiajun Wu,2019 AAAI/ACM SIGAI Dissertation Award,"Human intelligence is beyond pattern recognition. From a single image, we are able to explain what we see, reconstruct the scene in 3D, predict what's going to happen, and plan our actions accordingly. Artificial intelligence, in particular deep learning, still falls short in some preeminent aspects when compared with human intelligence, despite its phenomenal development in the past decade: they in general tackle specific problems, require large amounts of training data, and easily break when generalizing to new tasks or environments. In this dissertation, we study the problem of physical scene understanding-building versatile, data-efficient, and generalizable machines that learn to see, reason about, and interact with the physical world. The core idea is to exploit the generic, causal structure behind the world, including knowledge from computer graphics, physics, and language, in the form of approximate simulation engines, and to integrate them with deep learning. Here, learning plays a multifaceted role: models may learn to invert simulation engines for efficient inference; they may also learn to approximate or augment simulation engines for more powerful forward simulation. This dissertation consists of three parts, where we investigate the use of such a hybrid model for perception, dynamics modeling, and cognitive reasoning, respectively. In Part I, we use learning in conjunction with graphics engines to build an object-centered scene representation for object shape, pose, and texture. In Part II, in addition to graphics engines, we pair learning with physics engines to simultaneously infer physical object properties. We also explore learning approximate simulation engines for better flexibility and expressiveness. In Part III, we leverage and extend the models introduced in Parts I and II for concept discovery and cognitive reasoning by looping in a program execution engine. The enhanced models discover program-like structures in objects and scenes and, in turn, exploit them for downstream tasks such as visual question answering and scene manipulation.",38951883,38951882,https://dspace.mit.edu/handle/1721.1/128332,5-Feb,,,,Y,,Award-D2-,,,2019 AAAI/ACM SIGAI Dissertation Award,http://widget1.virtualchair.net/custom/aaai/jump?paperId=DISS-2019
